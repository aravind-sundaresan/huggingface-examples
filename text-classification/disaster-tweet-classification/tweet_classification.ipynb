{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweet-classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrl8U8Vq/NovHCW6Qd1olw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aravind-sundaresan/huggingface-examples/blob/master/tweet_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxHgAG04LQVT"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G1js5eLMrdM"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/drive\")\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from transformers import DistilBertTokenizerFast\n",
        "from transformers import TFDistilBertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLEDKXPsTlEA"
      },
      "source": [
        "## Loading the input data\n",
        "The input dataset consists of tweets pertaining to disasters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH-GPYjNNUMQ"
      },
      "source": [
        "tweet_df = pd.read_csv(\"data/tweets.csv\")\n",
        "\n",
        "tweet_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDVtjlwqViyl"
      },
      "source": [
        "Distribution of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-2dz432VBwr"
      },
      "source": [
        "tweet_df[\"target\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9VqzX_XWW1u"
      },
      "source": [
        "## Generating Train and Validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6kryTI3VGiE"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(tweet_df[\"text\"].values, tweet_df[\"target\"].values, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkaVY-oQe4uE"
      },
      "source": [
        "## Tokenizing the tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W559se-iWzh-"
      },
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7opHbmzfDE7"
      },
      "source": [
        "''' truncation=True and padding=True will ensure that all sequences are padded to the same length and \n",
        " are truncated to be no longer than the modelâ€™s maximum input length '''\n",
        "\n",
        "train_encodings = tokenizer(list(x_train), truncation=True, padding=True)\n",
        "val_encodings = tokenizer(list(x_val), truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuKIx0b6hFB1"
      },
      "source": [
        "## Creating a Dataset object using the encodings and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMUkvofkgCxV"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    y_train\n",
        "))\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    y_val\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW21wTlMnRUG"
      },
      "source": [
        "# Fine-tuning the pretrained model using native TensorFlow\n",
        "The classifier is built by fine-tuning a pre-trained DistilBert model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2j7TNkahUkM"
      },
      "source": [
        "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kq526UFouVa"
      },
      "source": [
        "model.fit(train_dataset.shuffle(1000).batch(16), epochs=5, validation_data=val_dataset.shuffle(1000).batch(16))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}